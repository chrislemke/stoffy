# Detailed Consciousness Theories Reference

## Global Workspace Theory (GWT)

### Historical Development
- **1988**: Bernard Baars introduces GWT in *A Cognitive Theory of Consciousness*
- **2000s**: Stanislas Dehaene and colleagues develop neural implementation
- **2010s**: Global Neuronal Workspace Theory (GNWT) becomes leading neuroscientific theory

### Core Architecture

```
                     GLOBAL WORKSPACE
                   ┌─────────────────┐
                   │  Conscious      │
                   │  Broadcast      │
                   └────────┬────────┘
                            │
          ┌─────────────────┼─────────────────┐
          │                 │                 │
    ┌─────▼─────┐     ┌─────▼─────┐     ┌─────▼─────┐
    │ Perceptual │     │  Memory   │     │   Motor   │
    │ Processors │     │  Systems  │     │  Planning │
    └───────────┘     └───────────┘     └───────────┘
          │                 │                 │
          └─────────────────┼─────────────────┘
                            │
                   ┌────────▼────────┐
                   │  Unconscious    │
                   │  Competition    │
                   └─────────────────┘
```

### Key Mechanisms

**Competition for Access**:
- Multiple unconscious processors compete for workspace access
- Only one "winner" gains global broadcast at a time
- Bottleneck explains limited capacity of consciousness

**Ignition**:
- When threshold crossed, activity "ignites" across frontal-parietal network
- All-or-none: either globally broadcast or remains unconscious
- Explains subjective boundary between conscious and unconscious

**Neural Implementation** (Dehaene):
- Workspace neurons: long-range connections, frontal-parietal
- Sensory processors: local connections, specialized
- Ignition: synchronous activation across distant brain regions

### Empirical Evidence

| Finding | Support for GWT |
|---------|-----------------|
| Attentional blink | Competition explains why second stimulus missed |
| Masking | Below-threshold stimuli don't ignite |
| Binocular rivalry | Alternation reflects competition for workspace |
| P300 wave | Neural signature of global broadcast |
| Frontal-parietal activation | Conscious access correlates with workspace regions |

### Strengths
- Clear neural predictions
- Explains access consciousness well
- Accounts for attention-consciousness link
- Testable empirical predictions

### Limitations
- Explains access but not phenomenality
- Why does broadcast FEEL like something?
- May conflate consciousness with attention
- Doesn't address the hard problem

---

## Integrated Information Theory (IIT)

### Core Framework (Tononi, 2004-present)

IIT takes phenomenology as primary and derives physical requirements.

### The Five Axioms (Phenomenological)

| Axiom | Description | Example |
|-------|-------------|---------|
| **Intrinsic Existence** | Consciousness exists from its own intrinsic perspective | I experience, therefore I am |
| **Composition** | Consciousness is structured (multiple elements in relations) | Visual field has parts |
| **Information** | Consciousness is specific (this experience, not others) | Seeing red, not blue |
| **Integration** | Consciousness is unified (cannot be divided without loss) | Experience is irreducibly whole |
| **Exclusion** | Consciousness has definite spatiotemporal grain | One experience now, not multiple |

### The Five Postulates (Physical Requirements)

Each axiom maps to a physical requirement:

| Axiom | Postulate |
|-------|-----------|
| Intrinsic Existence | System has causal power on itself |
| Composition | System has cause-effect structure |
| Information | System specifies a cause-effect repertoire |
| Integration | Cause-effect structure is integrated (cannot be reduced) |
| Exclusion | Maximum irreducibility determines boundaries |

### Phi (Φ)

**Definition**: Φ quantifies how much a system's cause-effect structure is integrated—how much is lost by partitioning.

**Calculation** (simplified):
1. Calculate full system's cause-effect repertoire
2. Calculate repertoire of minimum information partition (MIP)
3. Φ = distance between whole and MIP

**Key Property**: Φ is intrinsic—it doesn't depend on external observer.

### IIT's Key Claims

1. **Consciousness IS integrated information**: Φ doesn't correlate with consciousness; it IS consciousness
2. **Panpsychism**: Any system with Φ > 0 has some experience
3. **Cerebellum paradox**: Cerebellum has more neurons but less integration → less conscious
4. **Feedforward networks**: Have Φ = 0, thus no consciousness (regardless of computation)

### Empirical Predictions

| Prediction | Test |
|------------|------|
| Φ correlates with conscious level | Anesthesia studies, sleep |
| Cerebellum less conscious than cortex | Lesion studies |
| Feedforward AI not conscious | Philosophical argument |
| Perturbational Complexity Index (PCI) | TMS-EEG studies |

### Strengths
- Starts from phenomenology
- Quantitative measure
- Explains why consciousness isn't everywhere (requires integration)
- Explains binding (integration = unity)

### Limitations
- Φ is computationally intractable for large systems
- Panpsychism is counterintuitive to many
- Combination problem: how do small Φs combine?
- Axioms are debatable

---

## Higher-Order Theories (HOT)

### Core Idea

A mental state is conscious if and only if there is a higher-order representation of it.

### Variants

**Higher-Order Thought Theory (Rosenthal)**:
- First-order state: sees red
- Higher-order thought: "I am seeing red"
- Consciousness = having the higher-order thought

**Higher-Order Perception Theory (Lycan)**:
- Inner sense perceives first-order states
- Like perception but directed inward
- Consciousness = inner perception

**Self-Representationalism (Kriegel)**:
- State represents itself (no separate higher-order state)
- Conscious states are intrinsically self-representing
- Avoids infinite regress

### Arguments For HOT

1. **Explains unconscious mental states**: States without higher-order representation
2. **Explains introspection**: Higher-order representations are what we introspect
3. **Fits with cognitive science**: Meta-cognition is real

### Arguments Against HOT

1. **Regress worry**: Does the higher-order state need to be conscious?
2. **Misrepresentation**: What if higher-order thought misrepresents first-order state?
3. **Animal consciousness**: Do animals have higher-order thoughts?
4. **Phenomenality**: Does higher-order representation explain why there's "something it's like"?

---

## Predictive Processing (PP) and Consciousness

### Core Framework

The brain is a prediction machine that minimizes prediction error at multiple hierarchical levels.

### Hierarchical Predictive Coding

```
       HIGHER LEVELS
      ┌─────────────┐
      │  Predictions │ ────────────┐
      └──────┬──────┘              │
             │                     │
      ┌──────▼──────┐              │
      │  Comparison  │ ←─ Prediction Errors
      └──────┬──────┘              │
             │                     │
      ┌──────▼──────┐              │
      │  Predictions │ ────────────┤
      └──────┬──────┘              │
             │                     │
      ┌──────▼──────┐              │
      │    Input    │ ─────────────┘
      └─────────────┘
       LOWER LEVELS
```

### PP Approaches to Consciousness

**1. Controlled Hallucination (Seth)**
- Perception is the brain's "best guess" about causes
- We don't see the world directly; we see our model of it
- Consciousness = the brain hallucinating reality, controlled by sensory input

**2. Counterfactual Depth (Seth)**
- Consciousness correlates with richness of counterfactual predictions
- "What would happen if I did X?"
- Rich counterfactual space = rich consciousness

**3. Precision and Attention**
- Attention = increased precision on certain prediction errors
- Consciousness may require sufficient precision
- Explains attention-consciousness link

**4. Active Inference (Friston)**
- Action = making predictions come true
- Consciousness emerges from active inference loops
- Self = the process of maintaining Markov blanket

### Key Insights from PP

| Insight | Implication for Consciousness |
|---------|------------------------------|
| Perception is construction | We experience our models, not reality |
| Hierarchical processing | Different levels = different aspects of experience |
| Precision weighting | Explains selective attention and salience |
| Active inference | Consciousness tied to agency and embodiment |
| Interoception | Bodily predictions constitute emotional experience |

### PP and the Self

Seth's model of selfhood in PP:

```
SELFHOOD LEVELS
│
├── Narrative Self (autobiographical)
│       │
├── Volitional Self (agency, ownership)
│       │
├── Bodily Self (body representation)
│       │
└── Interoceptive Self (emotional, homeostatic)
        │
      BASE
```

Each level involves predictions about different aspects of being a self.

---

## Attention Schema Theory (AST)

### Core Claim (Graziano)

Consciousness is the brain's model of attention.

### The Attention Schema

- Brain controls attention (actual process)
- Brain models its own attention (attention schema)
- This model IS consciousness—simplified representation of attention
- We are aware because we model our own attention

### Key Move

AST explains consciousness as information about attention, not attention itself.

**Analogy**: The brain has a body schema (model of body position). Similarly, it has an attention schema (model of attention state).

### Implications

- Consciousness is a simplified model (like all models, partially inaccurate)
- Explains why we think consciousness is mysterious (model is simplified)
- Potentially testable: manipulate attention schema, change consciousness

---

## Enactivism and Embodied Approaches

### Core Claim

Consciousness isn't in the head—it emerges from brain-body-environment dynamics.

### Key Figures

- **Varela, Thompson, Rosch**: *The Embodied Mind*
- **Thompson**: *Mind in Life*
- **Noë**: *Action in Perception*

### Autopoiesis and Consciousness

Living systems are self-producing (autopoietic). Consciousness may be the subjective aspect of autopoietic self-maintenance.

**Thompson's Synthesis**:
- Life = autopoiesis
- Mind = sense-making (significance for the organism)
- Consciousness = experience of sense-making

### Implications

1. Consciousness requires embodiment
2. Disembodied AI wouldn't be conscious
3. Extended mind: consciousness may extend beyond brain
4. Environment partially constitutes consciousness

---

## Comparison Table

| Theory | What is Consciousness? | Where is Consciousness? | Hard Problem Solution |
|--------|----------------------|------------------------|----------------------|
| **GWT** | Global broadcast | Frontal-parietal workspace | Doesn't address |
| **IIT** | Integrated information (Φ) | Wherever Φ > 0 | Dissolves (identity claim) |
| **HOT** | Higher-order representation | Prefrontal cortex | Representation explains awareness |
| **PP** | Prediction/model | Hierarchical brain system | Controlled hallucination |
| **AST** | Attention schema | Attention system | Model explains intuitions |
| **Enactivism** | Sense-making | Brain-body-world | Life = mind = experience |
