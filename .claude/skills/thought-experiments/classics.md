# Classic Thought Experiments: Detailed Analysis

## Ethics

### The Trolley Problem (Foot, 1967; Thomson, 1985)

#### Scenario (Original)
A runaway trolley will kill five people on the track. You can pull a lever to divert it to a side track where it will kill one person.

#### Variants

**Switch**: Pull lever to divert trolley (most people: permissible)

**Footbridge**: Push fat man off bridge to stop trolley (most people: impermissible)

**Loop**: Trolley on loop track; will return and kill five unless blocked by one person on loop (contested)

**Transplant**: Kill one healthy patient to harvest organs for five dying patients (impermissible)

#### Target
- Doctrine of Double Effect (DDE)
- Using vs. merely involving
- Killing vs. letting die
- Consequentialism vs. deontology

#### Analysis

| Principle | Switch | Footbridge | Consistency? |
|-----------|--------|------------|--------------|
| **Pure consequentialism** | Permissible | Permissible | Consistent but counterintuitive |
| **DDE** | Permissible (death foreseen) | Impermissible (death intended) | Consistent |
| **Means/side-effect** | Permissible | Impermissible | Consistent |
| **Contact principle** | Permissible | Impermissible | Ad hoc? |

#### Hidden Assumptions
1. Numbers matter (five vs. one)
2. Certain death on each track
3. No other options available
4. Person on side track is innocent

#### What It Teaches
The trolley problem reveals that most people's moral intuitions don't reduce to simple consequentialism. We distinguish:
- Intended vs. foreseen harm
- Doing vs. allowing
- Physical contact vs. remote causation

---

### The Violinist (Thomson, 1971)

#### Scenario
You wake up connected to a famous violinist who will die if disconnected. The Society of Music Lovers kidnapped you because only your blood type can save him. He needs nine months of connection.

#### The Question
Are you morally required to remain connected?

#### Target
Right to life vs. bodily autonomy (abortion debate)

#### Variants
- What if only one hour required?
- What if you volunteered initially but changed your mind?
- What if disconnecting would actively kill (not just "letting die")?
- What if it's your child, not a stranger?

#### Analysis

| Position | Judgment | Reasoning |
|----------|----------|-----------|
| **Pro-bodily autonomy** | May disconnect | Right to control your body trumps |
| **Strong pro-life** | Must stay connected | Right to life is paramount |
| **Moderate** | Depends on duration/circumstances | Rights must be balanced |

#### Hidden Assumptions
1. Violinist is innocent (like a fetus)
2. Connection is the only way to save him
3. You had no choice in being connected

#### What It Teaches
Even granting fetal personhood, there may be limits to the obligations it generates. The argument separates:
- Right to life (to not be killed)
- Right to another's body (to be kept alive)

---

### The Experience Machine (Nozick, 1974)

#### Scenario
Scientists have built a machine that can give you any experiences you want. While floating in a tank, you'll believe you're writing great novels, making friends, or anything else. You can program your life's experiences in advance.

#### The Question
Would you plug in for life?

#### Target
Hedonism: Only experiences matter for well-being.

#### Variants
- What if everyone else is already plugged in?
- What if you could forget you made the choice?
- What if unplugging would kill you?
- What if the machine occasionally malfunctions?

#### Common Responses

| Response | Reasoning |
|----------|-----------|
| **No** | Reality matters; achievements must be real |
| **No** | Want to BE certain things, not just experience being them |
| **No** | Limiting: machines can only give pre-programmed experiences |
| **Yes** | What matters is how life feels; reality is overrated |
| **Status quo bias** | We only refuse because we're used to reality |

#### Hidden Assumptions
1. Machine is perfectly reliable
2. No one outside would miss you
3. You can't unplug once in

#### What It Teaches
Most people have non-hedonistic values:
- Achievement (actually doing things)
- Reality (contact with the real world)
- Personal development (becoming better)
- Relationships (with actual people)

---

## Epistemology

### Gettier Cases (Gettier, 1963)

#### Scenario (Case 1)
Smith has strong evidence that Jones will get the job and Jones has ten coins in his pocket. Smith forms the belief: "The man who will get the job has ten coins in his pocket." Unknown to Smith, he (Smith) will get the job, and Smith also happens to have ten coins in his pocket.

#### The Question
Does Smith KNOW that the man who will get the job has ten coins?

#### Target
Traditional analysis: Knowledge = Justified True Belief (JTB)

#### Structure of Gettier Cases
All share:
1. Subject has justified belief
2. Belief is true
3. But truth is accidental (wrong reason)
4. Intuitively: not knowledge

#### More Gettier Cases

**Fake Barns**: Driving through barn facade country, you point to the ONE real barn and say "That's a barn." True, justified, but knowledge?

**Stopped Clock**: You look at a clock that stopped exactly 12 hours ago, at the exact moment it shows. You believe it's 3:00 and it is 3:00.

**Lucky Lottery**: You believe your ticket lost (justified by odds), but actually you won and a computer error shows you losing.

#### Responses

| Response | Strategy |
|----------|----------|
| **Add fourth condition** | No false lemmas, no defeaters, etc. |
| **Reliabilism** | Knowledge = reliably produced true belief |
| **Virtue epistemology** | Knowledge = true belief from epistemic virtue |
| **Contextualism** | "Knowledge" standards vary by context |
| **Revise intuitions** | Maybe Gettier cases ARE knowledge |

#### What It Teaches
The simple JTB analysis fails. Knowledge requires more than lucky justified true belief. But what exactly is the "more"?

---

### Brain in a Vat (Putnam, 1981)

#### Scenario
Imagine you're a brain in a vat, stimulated by computers to have all your current experiences. You can't tell the difference from "real" embodiment.

#### The Question
Can you know you're not a brain in a vat?

#### Target
External world skepticism

#### Putnam's Response
If you were a brain in a vat, your word "brain" would refer to computer simulations of brains, not real brains. So "I am a brain in a vat" would be false by its own meaning.

#### Variants
- The Matrix version
- Recent envatment (you were embodied until yesterday)
- Partial envatment (some experiences real, some simulated)

#### What It Teaches
Skeptical scenarios reveal the gap between subjective experience and external reality. Even if we can't prove we're not envatted, we may still be rational in believing in the external world.

---

## Metaphysics

### Ship of Theseus (Plutarch)

#### Scenario
A ship's planks are replaced one at a time. Eventually, every plank has been replaced. Meanwhile, the old planks are assembled into a second ship.

#### The Question
Which ship (if either) is the original Ship of Theseus?

#### Variants
- **Gradual replacement**: Is the continuously maintained ship Theseus's?
- **Reconstructed ship**: Is the reassembled ship Theseus's?
- **Both ships exist**: Can two ships be the "same" ship?
- **Grandfather's Axe**: Replaced handle, then replaced head—same axe?

#### Positions

| Position | Answer | Criterion |
|----------|--------|-----------|
| **Continuity theory** | Continuously maintained ship | Spatiotemporal continuity |
| **Constitution theory** | Reassembled ship | Same matter |
| **Four-dimensionalism** | Both are temporal parts | Persistence is perdurance |
| **Conventionalism** | Neither/both; "same" is conventional | Identity is relative to interests |

#### What It Teaches
Identity over time is puzzling. What makes something the "same" thing through change? Different criteria (matter, form, continuity) can conflict.

---

### Teletransportation (Parfit, 1984)

#### Standard Case
A teleporter scans your body, destroys it, and creates an exact replica at Mars. The replica has all your memories, personality, beliefs.

#### The Question
Did YOU travel to Mars, or did you die and get replaced?

#### Variants

**Branch Line**: The scanner malfunctions. Your original body survives on Earth while a replica appears on Mars. Two yous?

**Gradual Replacement**: Neurons are replaced one by one with silicon. When (if ever) do you cease to exist?

**Fission**: The teleporter creates two replicas. Which one is you?

#### Positions

| Position | Standard Case | Branch Line |
|----------|---------------|-------------|
| **Psychological continuity** | You survive | Fork—both are you? |
| **Biological** | You die | Original survives |
| **Pattern identity** | You survive | Fork—identity splits |
| **No-self** | Question confused | No determinate answer |

#### What Parfit Argued
Personal identity doesn't matter as much as we think. What matters is psychological continuity, which can hold in degrees and can branch. "Survival" isn't all-or-nothing.

---

## Philosophy of Mind

### Mary's Room (Jackson, 1982)

See `philosophy-of-mind/thought_experiments.md` for full analysis.

**Key Points**:
- Mary knows all physical facts about color
- Mary has never seen color
- When she sees red, does she learn something new?
- If yes: there are non-physical facts
- Challenge to physicalism

---

### Chinese Room (Searle, 1980)

See `philosophy-of-mind/thought_experiments.md` for full analysis.

**Key Points**:
- Person follows rules to manipulate Chinese symbols
- Appears to understand Chinese to outsiders
- Person understands nothing
- Conclusion: Syntax isn't sufficient for semantics
- Challenge to Strong AI

---

### Philosophical Zombies (Chalmers, 1996)

See `philosophy-of-mind/thought_experiments.md` for full analysis.

**Key Points**:
- Physical duplicate with no consciousness
- If conceivable → possibly possible
- If possible → physicalism false
- Debate: Are zombies genuinely conceivable?

---

## Political Philosophy

### Original Position (Rawls, 1971)

#### Scenario
Imagine choosing principles of justice from behind a "veil of ignorance"—you don't know your place in society, your talents, your conception of the good, or even your generation.

#### The Question
What principles would you choose?

#### Rawls's Answer
1. Equal basic liberties for all
2. Social/economic inequalities arranged to benefit least advantaged (difference principle)

#### Why It Works
The veil of ignorance forces impartiality. You'd choose fair principles because you might end up anywhere in the resulting society.

#### Critiques
- **Communitarianism**: Can't abstract from particular identities
- **Libertarianism**: Violates self-ownership
- **Feminist**: Ignores family/private sphere
- **Risk preferences**: Different people might choose differently under uncertainty

#### What It Teaches
A powerful method for thinking about justice: What would we choose if we couldn't bias the outcome in our favor?

---

### Drowning Child (Singer, 1972)

#### Scenario
You walk past a shallow pond and see a child drowning. You can easily save the child, but your expensive shoes will be ruined.

#### The Question
Are you morally required to save the child (at the cost of your shoes)?

#### The Expansion
Most people: Yes, obviously. Singer: Then why don't you give to prevent distant deaths you could prevent at similar cost?

#### Target
Distinction between near and far moral obligations

#### Responses
- **Accept**: We SHOULD give much more (Singer's view)
- **Reject analogy**: Distance/directness matters
- **Demandingness objection**: Morality can't require that much
- **Institutional response**: Poverty is a political problem, not individual

#### What It Teaches
Our intuitions about helping may be inconsistent. The drowning child case challenges us to either expand our obligations or explain why distance matters.
